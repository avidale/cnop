{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот блокнот показывает, как можно построить модель Cross-Nested Ordered Probit на PyTorch, обучить её на своих данных, и провести оценку значимости коэффициентов. \n",
    "\n",
    "Подробности: https://habr.com/ru/post/548100/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разминки, накодим обычный Ordered Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class OrderedProbitHead(nn.Module):\n",
    "    \"\"\" A layer transforming a vector of hidden states into a matrix of probabilities.\n",
    "    Input size: [batch, 1]\n",
    "    Output size: [batch, levels]\n",
    "    \"\"\"\n",
    "    def __init__(self, levels):\n",
    "        super(OrderedProbitHead, self).__init__()\n",
    "        assert levels >= 3\n",
    "        self.levels = levels\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "        self.log_difs = nn.Parameter(torch.randn(levels - 2))\n",
    "        self.activation = torch.distributions.normal.Normal(0, 1).cdf\n",
    "\n",
    "    @property\n",
    "    def cutpoints(self):\n",
    "        diffs = torch.cat([torch.tensor([0]), torch.exp(self.log_difs)], 0)\n",
    "        return self.bias + torch.cumsum(diffs, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cdfs = self.activation(self.cutpoints - x)  \n",
    "        lhs = torch.cat([cdfs, torch.ones_like(x)], 1)\n",
    "        rhs = torch.cat([torch.zeros_like(x), cdfs], 1)\n",
    "        return lhs - rhs\n",
    "\n",
    "\n",
    "class OrderedProbitModel(nn.Module):\n",
    "    \"\"\" A model transforming a vector of features into a matrix of probabilities\n",
    "    Input size: [batch, features]\n",
    "    Output size: [batch, levels]\n",
    "    \"\"\"\n",
    "    def __init__(self, features, levels, smoothing=1e-10):\n",
    "        super(OrderedProbitModel, self).__init__()\n",
    "        self.levels = levels\n",
    "        self.dense = nn.Linear(features, 1, bias=False)\n",
    "        self.head = OrderedProbitHead(levels)\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x):\n",
    "        probas = self.head(self.dense(x))\n",
    "        if self.smoothing:\n",
    "            probas = (1 - self.smoothing) * probas + self.smoothing * torch.ones_like(probas) / self.levels\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем на игрушечных данных и убеждаемся, что все коэффициенты оцениваются верно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = np.array([-1, 1])\n",
    "slopes = np.array([1, 0])\n",
    "\n",
    "np.random.seed(1)\n",
    "n = 10000\n",
    "X = np.random.normal(size=[n, 2])\n",
    "ss = np.dot(X, slopes) + np.random.normal(size=n)\n",
    "y = (ss[:, np.newaxis] < cuts).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.tensor(X, dtype=torch.float)\n",
    "yy = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "def train(model, x, y, steps=300, lr=0.1, max_norm=1.0, wd=1e-6):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    pbar = trange(steps)\n",
    "    for i in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        proba = model(x)\n",
    "        loss = loss_fn(torch.log(proba), y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(op.parameters(), max_norm)\n",
    "        pbar.set_description(f\"Loss: {loss.item():2.10f}\")\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d21ffc9187a4bb997e259fb5d89ca12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "op = OrderedProbitModel(features=2, levels=3)\n",
    "train(op, xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense.weight \t tensor([[-1.0323,  0.0040]])\n",
      "head.bias \t tensor([-1.0201])\n",
      "head.log_difs \t tensor([0.7024])\n",
      "tensor([-1.0201,  0.9985], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, param in op.named_parameters():\n",
    "    print(name, '\\t', param.data)\n",
    "print(op.head.cutpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rate_change</th>\n",
       "      <th>pb</th>\n",
       "      <th>spread</th>\n",
       "      <th>houst</th>\n",
       "      <th>gdp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5/18/1992</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.120</td>\n",
       "      <td>1.21</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1/31/1991</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.918</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>11/16/1998</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.542</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>11/14/2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>1.56</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>12/05/1991</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  rate_change  pb  spread  houst  gdp  target\n",
       "67    5/18/1992         0.00  -1   0.120   1.21  4.9       2\n",
       "48    1/31/1991        -0.50  -1  -0.918   1.00  3.3       0\n",
       "123  11/16/1998        -0.25  -1  -0.542   1.57  3.2       1\n",
       "139  11/14/2000         0.00   1  -0.394   1.56  5.9       2\n",
       "62   12/05/1991        -0.25  -1  -0.190   1.02  3.5       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://github.com/avidale/cnop/blob/master/application/rate_change.dta?raw=true'\n",
    "data = pd.read_stata(url)\n",
    "data['target'] = data.rate_change.apply(lambda x: int(x * 4 + 2))\n",
    "print(data.shape)\n",
    "x = torch.tensor(data[['spread', 'pb', 'houst', 'gdp']].values)\n",
    "y = torch.tensor(data.target)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be75575518a942c6a7da70d2feb3192a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "op = OrderedProbitModel(features=4, levels=5, smoothing=1e-10)\n",
    "train(op, x, y)\n",
    "# Loss: 0.7598916888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициенты получаются такие же, как [в статье](https://www.hse.ru/data/2018/05/30/1149326878/193EC2018.pdf) (на 18 странице)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5743, 0.9265, 1.3694, 0.2389]])\n",
      "tensor([0.4595, 1.8323, 4.8293, 6.3243])\n"
     ]
    }
   ],
   "source": [
    "print(op.dense.weight.data)\n",
    "# tensor([[0.9262, 1.5742, 1.3730, 0.2391]])\n",
    "print(op.head.cutpoints.data)\n",
    "# tensor([0.4655, 1.8380, 4.8357, 6.3309])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С моделью CNOP чуть сложнее: там функция правдоподобия не является глобально выпуклой, и иногда обучение застревает в плохом локальном оптимуме. Чтобы получить надёжный результат, лучше запустить функцию обучения несколько раз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1ca978e62f441fae4d53bc4f89db6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class CrossNestedOrderedProbitModel(nn.Module):\n",
    "    \"\"\" A model transforming a vector of features into a matrix of probabilities.\n",
    "    The model uses a neutral category (center), \n",
    "    negative categories (from 0 to center -1),\n",
    "    and positive categories (from center + 1 to levels - 1).\n",
    "    For each group of categories, parameters are different.\n",
    "    Input size: [batch, features]\n",
    "    Output size: [batch, levels]\n",
    "    \"\"\"\n",
    "    def __init__(self, features, levels, center, smoothing=1e-10):\n",
    "        super(CrossNestedOrderedProbitModel, self).__init__()\n",
    "        self.features = features\n",
    "        self.levels = levels\n",
    "        self.center = center\n",
    "        self.smoothing = smoothing\n",
    "        self.dense = nn.Linear(features, 3, bias=False)\n",
    "        self.head_zero = OrderedProbitHead(3)\n",
    "        self.head_neg = OrderedProbitHead(center + 1)\n",
    "        self.head_pos = OrderedProbitHead(levels - center)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        dense = self.dense(x)\n",
    "        nzp = self.head_zero(dense[:, [0]])\n",
    "        negative = self.head_neg(dense[:, [1]])\n",
    "        positive = self.head_pos(dense[:, [2]])\n",
    "        probas = torch.zeros([x.shape[0], self.levels])\n",
    "        probas[:, self.center] += nzp[:, 1]\n",
    "        probas[:, :(self.center+1)] += nzp[:, [0]] * negative\n",
    "        probas[:, self.center:] += nzp[:, [2]] * positive\n",
    "        if self.smoothing:\n",
    "            probas = (1-self.smoothing) * probas + self.smoothing * torch.ones_like(probas) / self.levels\n",
    "        return probas\n",
    "    \n",
    "cnop = CrossNestedOrderedProbitModel(features=4, levels=5, center=2)\n",
    "train(cnop, x, y, lr=0.1, steps=10000)\n",
    "# Loss: 0.6336604357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7523809523809524"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cnop(x).argmax(1) == y).numpy().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_errors(model, loss):\n",
    "    all_params = torch.cat([p.view(-1) for p in model.parameters()])\n",
    "    hessian = torch.empty(all_params.shape * 2)\n",
    "\n",
    "    first_order_grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True, create_graph=True)\n",
    "\n",
    "    c = 0\n",
    "    for i, (name, param) in enumerate(model.named_parameters()):\n",
    "        v = param.view(-1)\n",
    "        g = first_order_grads[i].view(-1)\n",
    "        var = torch.empty_like(v)\n",
    "        for j, gg in enumerate(g):\n",
    "            hh = torch.autograd.grad(gg, model.parameters(), retain_graph=True)\n",
    "            hessian[c] = torch.cat([p.view(-1) for p in hh])\n",
    "            c += 1\n",
    "\n",
    "    standard_deviations = torch.diag(torch.inverse(hessian)) ** 0.5\n",
    "\n",
    "    result = []\n",
    "    start = 0\n",
    "    for i, (name, param) in enumerate(model.named_parameters()):\n",
    "        v = param.view(-1)\n",
    "        n = v.shape[0]\n",
    "        ss = standard_deviations[start:start+n].view(param.shape)\n",
    "        result.append(ss)\n",
    "        start += n\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>std</th>\n",
       "      <th>t</th>\n",
       "      <th>p-value</th>\n",
       "      <th>[2.5%</th>\n",
       "      <th>97.5%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dense.weight[0]</th>\n",
       "      <td>1.5743</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>8.4159</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.2077</td>\n",
       "      <td>1.9410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[1]</th>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>6.2629</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>1.2164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[2]</th>\n",
       "      <td>1.3694</td>\n",
       "      <td>0.3459</td>\n",
       "      <td>3.9593</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>2.0473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[3]</th>\n",
       "      <td>0.2389</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>4.1779</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.3510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head.bias</th>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.3932</td>\n",
       "      <td>-0.5953</td>\n",
       "      <td>1.5143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head.log_difs[0]</th>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>2.1770</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.6022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head.log_difs[1]</th>\n",
       "      <td>1.0976</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>12.3879</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>1.2713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head.log_difs[2]</th>\n",
       "      <td>0.4021</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>2.7508</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.1156</td>\n",
       "      <td>0.6886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   value     std        t  p-value   [2.5%  97.5%]\n",
       "dense.weight[0]   1.5743  0.1871   8.4159   0.0000  1.2077  1.9410\n",
       "dense.weight[1]   0.9265  0.1479   6.2629   0.0000  0.6365  1.2164\n",
       "dense.weight[2]   1.3694  0.3459   3.9593   0.0001  0.6915  2.0473\n",
       "dense.weight[3]   0.2389  0.0572   4.1779   0.0000  0.1268  0.3510\n",
       "head.bias         0.4595  0.5382   0.8538   0.3932 -0.5953  1.5143\n",
       "head.log_difs[0]  0.3169  0.1456   2.1770   0.0295  0.0316  0.6022\n",
       "head.log_difs[1]  1.0976  0.0886  12.3879   0.0000  0.9239  1.2713\n",
       "head.log_difs[2]  0.4021  0.1462   2.7508   0.0059  0.1156  0.6886"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def report(model, loss):\n",
    "    result = []\n",
    "    names = []\n",
    "    se = get_standard_errors(model, loss)\n",
    "    for i, (name, param) in enumerate(model.named_parameters()):\n",
    "        shape = param.squeeze().shape\n",
    "        v = param.view(-1).detach().numpy()\n",
    "        s = se[i].view(-1).detach().numpy()\n",
    "        for j, (vv, ss) in enumerate(zip(v, s)):\n",
    "            t = np.abs(vv / ss)\n",
    "            result.append({\n",
    "                'value': vv,\n",
    "                'std': ss,\n",
    "                't': t,\n",
    "                'p-value': norm.cdf(-t) * 2,\n",
    "                '[2.5%': vv-ss*1.96,\n",
    "                '97.5%]': vv+ss*1.96,\n",
    "            })\n",
    "            if len(v) > 1:\n",
    "                names.append(f'{name}{list(np.unravel_index(j, shape))}')\n",
    "            else:\n",
    "                names.append(name)\n",
    "    return pd.DataFrame(result, index=names)\n",
    "\n",
    "\n",
    "likelihood = nn.CrossEntropyLoss(reduction='sum')\n",
    "report(op, likelihood(torch.log(op(x)), y)).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>std</th>\n",
       "      <th>t</th>\n",
       "      <th>p-value</th>\n",
       "      <th>[2.5%</th>\n",
       "      <th>97.5%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dense.weight[0, 0]</th>\n",
       "      <td>2.0720</td>\n",
       "      <td>0.3878</td>\n",
       "      <td>5.3433</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3120</td>\n",
       "      <td>2.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[0, 1]</th>\n",
       "      <td>1.3717</td>\n",
       "      <td>0.4164</td>\n",
       "      <td>3.2938</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.5554</td>\n",
       "      <td>2.1879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[0, 2]</th>\n",
       "      <td>5.7803</td>\n",
       "      <td>1.1166</td>\n",
       "      <td>5.1767</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.5917</td>\n",
       "      <td>7.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[0, 3]</th>\n",
       "      <td>0.4283</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>3.4688</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>0.6703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[1, 0]</th>\n",
       "      <td>1.0465</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>3.5603</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>1.6226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[1, 1]</th>\n",
       "      <td>0.5979</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>1.7427</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>-0.0745</td>\n",
       "      <td>1.2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[1, 2]</th>\n",
       "      <td>-0.5598</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>-1.9342</td>\n",
       "      <td>0.8145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[1, 3]</th>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>1.8123</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>0.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[2, 0]</th>\n",
       "      <td>3.0320</td>\n",
       "      <td>1.1782</td>\n",
       "      <td>2.5733</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>5.3413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[2, 1]</th>\n",
       "      <td>3.6257</td>\n",
       "      <td>1.3942</td>\n",
       "      <td>2.6006</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>6.3583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[2, 2]</th>\n",
       "      <td>-3.9003</td>\n",
       "      <td>3.2663</td>\n",
       "      <td>1.1941</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>-10.3023</td>\n",
       "      <td>2.5016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense.weight[2, 3]</th>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.3702</td>\n",
       "      <td>1.8401</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>-0.0444</td>\n",
       "      <td>1.4068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head_zero.bias</th>\n",
       "      <td>10.4198</td>\n",
       "      <td>2.2295</td>\n",
       "      <td>4.6737</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0500</td>\n",
       "      <td>14.7896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head_zero.log_difs</th>\n",
       "      <td>1.0202</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>3.7272</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.4837</td>\n",
       "      <td>1.5567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head_neg.bias</th>\n",
       "      <td>-1.9381</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>2.1451</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>-3.7089</td>\n",
       "      <td>-0.1673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head_neg.log_difs</th>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>2.0358</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.6149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head_pos.bias</th>\n",
       "      <td>-4.6615</td>\n",
       "      <td>7.1157</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>-18.6082</td>\n",
       "      <td>9.2853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head_pos.log_difs</th>\n",
       "      <td>2.1056</td>\n",
       "      <td>0.3338</td>\n",
       "      <td>6.3072</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.4513</td>\n",
       "      <td>2.7599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      value     std       t  p-value    [2.5%   97.5%]\n",
       "dense.weight[0, 0]   2.0720  0.3878  5.3433   0.0000   1.3120   2.8321\n",
       "dense.weight[0, 1]   1.3717  0.4164  3.2938   0.0010   0.5554   2.1879\n",
       "dense.weight[0, 2]   5.7803  1.1166  5.1767   0.0000   3.5917   7.9688\n",
       "dense.weight[0, 3]   0.4283  0.1235  3.4688   0.0005   0.1863   0.6703\n",
       "dense.weight[1, 0]   1.0465  0.2939  3.5603   0.0004   0.4704   1.6226\n",
       "dense.weight[1, 1]   0.5979  0.3431  1.7427   0.0814  -0.0745   1.2703\n",
       "dense.weight[1, 2]  -0.5598  0.7012  0.7984   0.4246  -1.9342   0.8145\n",
       "dense.weight[1, 3]   0.1381  0.0762  1.8123   0.0699  -0.0113   0.2875\n",
       "dense.weight[2, 0]   3.0320  1.1782  2.5733   0.0101   0.7226   5.3413\n",
       "dense.weight[2, 1]   3.6257  1.3942  2.6006   0.0093   0.8932   6.3583\n",
       "dense.weight[2, 2]  -3.9003  3.2663  1.1941   0.2324 -10.3023   2.5016\n",
       "dense.weight[2, 3]   0.6812  0.3702  1.8401   0.0658  -0.0444   1.4068\n",
       "head_zero.bias      10.4198  2.2295  4.6737   0.0000   6.0500  14.7896\n",
       "head_zero.log_difs   1.0202  0.2737  3.7272   0.0002   0.4837   1.5567\n",
       "head_neg.bias       -1.9381  0.9035  2.1451   0.0319  -3.7089  -0.1673\n",
       "head_neg.log_difs    0.3133  0.1539  2.0358   0.0418   0.0117   0.6149\n",
       "head_pos.bias       -4.6615  7.1157  0.6551   0.5124 -18.6082   9.2853\n",
       "head_pos.log_difs    2.1056  0.3338  6.3072   0.0000   1.4513   2.7599"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(cnop, likelihood(torch.log(cnop(x)), y)).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
