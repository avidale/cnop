
\documentclass[letterpaper,fleqn,11pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{geometry}
\usepackage[singlespacing]{setspace}
\usepackage{amsfonts}
\usepackage{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{accents}
\usepackage{eurosym}
\usepackage{amssymb}
\usepackage{rotating}
\usepackage{sectsty}
\usepackage{endnotes}
\usepackage{chbibref}
\usepackage{float}
\usepackage{nopageno}
\usepackage[labelsep=period]{caption}
\usepackage{scalefnt}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{<META NAME="SaveForMode" CONTENT="2">}
%TCIDATA{BibliographyScheme=Manual}
%TCIDATA{Created=Wednesday, April 07, 2010 09:52:31}
%TCIDATA{LastRevised=Monday, August 21, 2017 22:00:12}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Standard LaTeX\Blank - Standard LaTeX Article">}
%TCIDATA{Language=American English}
%TCIDATA{CSTFile=40 LaTeX article.cst}

\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\geometry{left=1.5 in,right=1 in,top=1 in,bottom=1.1 in}
\input{tcilatex}
\setlength{\abovecaptionskip}{3pt}
\makeatletter
\def\@biblabel#1{\hspace*{-\labelsep}}
\newdimen\@bibhang \@bibhang=2em
\def\setbibhang#1{\@bibhang=#1}
\renewenvironment{thebibliography}[1]{  \setlength{\labelwidth}{0pt}
  \setlength{\labelsep}{0pt}
  \section*{\refname
     \@mkboth{\uppercase{\refname}}{\uppercase{\refname}}}   \vspace{0em}
   \setlength{\parindent}{0pt}
   \def\newblock{}
   \renewcommand{\bibitem}[2][]{     \if@filesw
       {\let\protect\noexpand\immediate
        \write\@auxout{\string\bibcite{##2}{##1}}}
        \fi\hangindent=\@bibhang\hangafter=1}}
\makeatother

\begin{document}

\title{Estimation of nested, zero-inflated and cross-nested ordered probit
models in STATA\\
\bigskip \bigskip }
\author{David Dale and Andrei Sirchenko}
\date{March 13, 2017}
\maketitle

\begin{abstract}
TBA

\bigskip \bigskip \bigskip \bigskip

\textit{JEL classification:} \bigskip .

\textit{Keywords:} ordinal responses, zero-inflated outcomes, two- and
three-part mixture model, endogenous regime switching.
\end{abstract}

%TCIMACRO{\TeXButton{Onehalf}{\begin{onehalfspace}}}%
%BeginExpansion
\begin{onehalfspace}%
%EndExpansion

\section{Introduction}

TBA...

\section{Econometric framework}

Left out

\section{Stata commands}

\subsection*{Syntax of the cnop, miop, and nop commands}

%\subsubsection{Syntax}

\hangindent=\parindent
\noindent \texttt{cnop $depvar$ $indepvars$ [$if$] [$in$] [, zp($varlist$)
zn($varlist$) infcat($integer$ $0$) correlated cluster($varname$) robust
initial($string$)] }

This command fits a cross-nested ordered probit model with possibly
different sets of covariates for each stage and possibly correlated errors
by maximum likelihood.

\hangindent=\parindent
\noindent \texttt{miop $depvar$ $indepvars$ [$if$] [$in$] [, z ($varlist$)
infcat($integer$ $0$) correlated cluster($varname$) robust initial($string$%
)] }

This command fits a middle-inflated ordered probit model.

\hangindent=\parindent
\noindent \texttt{nop $depvar$ $indepvars$ [$if$] [$in$] [, zp($varlist$) zn(%
$varlist$) infcat($integer$ $0$) correlated cluster($varname$) robust
initial($string$)] }

This command fits a nested ordered probit model.

%\subsubsection{Description}

\subsubsection*{Options}

\begin{tabular}{lp{12cm}}
\textit{options} & Description \\ 
\midrule \texttt{zp($varlist$)} & list of covariates for positive response
in NOP and CNOP models; by default, it equals $indepvars$, the list of
covariates for initial stage \\ 
\texttt{zn($varlist$)} & list of covariates for negative response in NOP and
CNOP models; by default, it equals $indepvars$, the list of covariates for
initial stage \\ 
\texttt{z($varlist$)} & list of covariates for non-zero response in ZIOP
models; by default, it equals $indepvars$, the list of covariates for
initial stage \\ 
\texttt{infcat($integer$)} & value of the response variable that should be
modeled as inflated; by default, it equals 0 \\ 
\texttt{correlated} & flag that errors in the first and second stages may be
correlated, forcing estimation of CNOPc, NOPc or ZIOPc model \\ 
\texttt{robust} & flag that variance-covariance estimator must be robust
(based on ``sandwich``) estimate \\ 
\texttt{cluster($varname$)} & clustering variable for robust variance
estimator \\ 
\texttt{initial($string$)} & whitespace-delimited list of initial parameter
values for estimation, in the following order: $\beta$, $\alpha$, $\gamma^{+}
$, $\mu^{+}$, $\gamma^{-}$, $\mu^{-}$, $\rho^{-}$, $\rho^{+}$%
\end{tabular}

\subsubsection*{Examples}

TBD

\subsubsection*{Stored results}

\texttt{cnop}, \texttt{nop}, and \texttt{miop} store the following in 
\texttt{e()}:

%Scalars

\begin{tabular}{p{3cm}p{12cm}}
\texttt{e(N)} & number of observations%
\end{tabular}

%Macros

\begin{tabular}{p{3cm}p{12cm}}
\texttt{e(cmd)} & \texttt{cnop}, \texttt{nop}, or \texttt{miop}, respectively
\\ 
\texttt{e(depvar)} & dependent variable of regression%
\end{tabular}

%Matrices

\begin{tabular}{p{3cm}p{12cm}}
\texttt{e(b)} & parameters vector \\ 
\texttt{e(V)} & variance-covariance matrix%
\end{tabular}

%Functions

\begin{tabular}{p{3cm}p{12cm}}
\texttt{e(sample)} & marks estimation sample%
\end{tabular}

\subsection*{CNOP postestimation commands}

\subsubsection*{The predict command}

The \texttt{predict} command after \texttt{cnop}, \texttt{nop}, and \texttt{%
miop} estimation commands produces either predicted probabilities or
expected value of the response.

\texttt{predict $varname$ [$if$] [$in$] [, zeroes regime output($string$) at(%
$string$)]}

\texttt{name} is the name of predicted variable, if it is single, or prefix
for names, if there are several predicted variables

\texttt{zeroes} indicates that different types of zeroes (i.e. ``intrinsic
zeroes``, or ``positive zeroes``, or ``negative zeroes``) must be predicted
instead of different response values.

\texttt{regime} indicates that different groups of response (negative,
positive or zero) must be predicted instead of different response values.
This option is ignored if \texttt{zeroes} option is on.

\texttt{output(string)} specifies type of aggregating predicted
probabilities of different response. Possible values are \texttt{mode} and 
\texttt{mean}, for predicting average or most probable outcome, and \texttt{%
cum} for predicting cumulative response probabilities (i.e. $p(y <=-2)$, $%
p(y<=-1)$, $p(y<=0)$ etc.). If not specified, raw response probabilities are
predicted ($p(y=-2)$, $p(y=-1)$, $p(y=0)$ etc.).

\subsubsection*{The cnopmargins command}

\texttt{cnopmargins [, at($string$) nominal($varlist$) zeroes regime]}

This command prints marginal effects for the last estimated CNOP, MIOP or
NOP model, calculated at the specified point, along with confidence
intervals.

\texttt{at(string)} specifies at which point predictions must be calculated.
If at is specified, (as a list of \texttt{varname=value} expressions,
separated by comma), prediction is calculated at this point and posted on
the screen without saving to the dataset. If some covariate names are not
specified, their mean value is taken instead.

\texttt{nominal} is a space-separated list of covariates which should be
considered as nominal; marginal effect is then calculated as difference
between values at 0 and at 1.

\texttt{zeroes} and \texttt{regime} indicate that marginal effects should be
calculated for different zeroes or for groups of response variable, as in 
\texttt{predict} command.

\subsubsection*{The cnopprobabilities command}

\texttt{cnopprobabilities [, at($string$) zeroes regime]}

This command prints predicted probabilities for the last estimated CNOP,
MIOP or NOP model, calculated at the specified point, along with confidence
intervals. The point \texttt{at} is specified like in \texttt{cnopmargins}.

\subsubsection*{The cnopcontrasts command}

\texttt{cnopcontrasts [, at($string$) to($string$) zeroes regime] }

This command prints differences in predicted probabilities for the last
estimated CNOP, MIOP or NOP model, calculated between the specified points,
along with confidence intervals. The points \texttt{at} and \texttt{to} are
specified like \texttt{at} in \texttt{cnopmargins}.

\subsubsection*{Examples}

TBD

\section{Finite sample performance}

We conducted extensive Monte Carlo experiments to illustrate the finite
sample performance of the ML estimators in the proposed models.

\subsection*{Monte Carlo design}

We conducted simulations for six data-generating processes (\textit{dgp):}
NOP, NOPc, ZIOP (MIOP version), ZIOPc (MIOPc version), CNOP, and CNOPc. The
data were generated and then estimated by the same model. For each dgp we
generated samples with 200, 500 and 1000 observations. The number of
replications was 10,000 in each experiment.

Three vectors of covariates $\mathbf{v}_{\mathbf{1}}$, $\mathbf{v}_{\mathbf{2%
}}$ and $\mathbf{v}_{\mathbf{3}}$ were drawn in each replication
as\noindent\ $\mathbf{v}_{\mathbf{1}}\overset{\emph{iid}}{\sim }\emph{Normal}%
(0,1)+2$, $\mathbf{v}_{\mathbf{2}}\overset{\emph{iid}}{\sim }\emph{Normal}%
(0,1$), and $\mathbf{v}_{\mathbf{3}}=-1$ if $\mathbf{w}\leq 0.3$, $0$ if $%
0.3<\mathbf{w}\leq 0.7$, or $1$ if $\mathbf{w}>0.7$, where $\mathbf{w}%
\overset{\emph{iid}}{\sim }\emph{Uniform}[0,1]$. The dependent variable was
generated with five outcome categories: -2, -1, 0, 1 and 2. The values of
the parameters were calibrated to yield on average the following frequencies
of the above outcomes: 7\%, 14\%, 58\%, 14\% and 7\%, respectively. To avoid
the divergence of ML estimates due to the problem of complete separation
(perfect prediction), which could happen if actual number of observations in
some outcome category (specifically, -2 and 2) is very low, the samples with
any category frequency lower than 6\% were re-generated. At each iteration
we checked that there is at least 6\% of observations in each outcome
category. The matrix of the PE, therefore, has $3\times 5=15$ elements;
their values, which depend on the values of the explanatory variables, are
computed at the population medians of the covariates. The observations in
repeated samples were drawn independently. The vectors of disturbance terms
in the latent equations were repeatedly generated as iid\emph{\ }$\emph{%
Normal}(0,1)$ random variables in the case of the NOP, ZIOP and CNOP \textit{%
dgp}. In the case of the NOPc and CNOPc models, the errors $\mathbf{\nu }$
in the inclination equation were generated as iid\emph{\ }$\emph{Normal}(0,1)
$ random variables, but the errors $\mathbf{\varepsilon }^{-}$ and $\mathbf{%
\varepsilon }^{+}$ in the amount equations were drawn so that $(\mathbf{\nu }%
,\mathbf{\varepsilon }^{-})$ and $(\mathbf{\nu },\mathbf{\varepsilon }^{+})$
are the standardized bivariate normal iid random variables with the
correlation coefficients $\rho ^{-}$ and $\rho ^{+},$ respectively. In the
ZIOPc dgp, the errors $\mathbf{\nu }^{0}$ in the participation equation were
generated as IID\emph{\ }$\emph{Normal}(0,1$) random variables, but the
errors $\mathbf{\varepsilon }^{0}$ in the amount equation were drawn so that 
$(\mathbf{\nu }^{0},\mathbf{\varepsilon }^{0})$ are the standardized
bivariate normal iid random variables with the correlation coefficients $%
\rho ^{0}$. The repeated samples were generated for the NOP, NOPc, CNOP and
CNOPc \textit{dgp }with $\mathbf{X=(v_{1}},\mathbf{v_{2}}$), $\mathbf{%
\mathbf{Z}^{-}=(v_{1}},\mathbf{v_{3}}$), $\mathbf{\mathbf{Z}^{+}=(v_{2}},%
\mathbf{v_{3}}$), and for the ZIOP and ZIOPc dgp with $\mathbf{X}^{0}\mathbf{%
=(v}_{1},\mathbf{v}_{3})$, $\mathbf{\mathbf{Z}}^{0}\mathbf{=(v}_{2},\mathbf{v%
}_{3})$. The true values of the simulation parameters are shown in Table \ref%
{tab:params}.

% Table generated by Excel2LaTeX from sheet 'params'

\begin{table}[htbp]
\caption{True values of parameters for simulation}
\label{tab:params}{\tiny \ \centering
\begin{tabular}{lcccccc}
\toprule & NOP & NOPc & ZIOP & ZIOPc & CNOP & CNOPc \\ 
\midrule $\mathbf{\beta }$ & (0.6, 0.4)$^{\prime }$ & (0.6, 0.4)$^{\prime }$
& (0.6, 0.8)$^{\prime }$ & (0.6, 0.8)$^{\prime }$ & (0.6, 0.4)$^{\prime }$ & 
(0.6, 0.4)$^{\prime }$ \\ 
$\mathbf{\alpha }$ & (0.21, 2.19)$^{\prime }$ & (0.21, 2.19)$^{\prime }$ & 
0.45 & 0.45 & (0.9, 1.5)$^{\prime }$ & (0.9, 1.5)$^{\prime }$ \\ 
$\mathbf{\gamma }^{-}$ & (0.2, 0.3)$^{\prime }$ & (0.2, 0.3)$^{\prime }$ & 
&  & (0.2, 0.3)$^{\prime }$ & (0.2, 0.3)$^{\prime }$ \\ 
$\mathbf{\gamma }^{+}$ & (0.3, 0.9)$^{\prime }$ & (0.3, 0.9)$^{\prime }$ & 
&  & (0.3, 0.9)$^{\prime }$ & (0.3, 0.9)$^{\prime }$ \\ 
$\mathbf{\mu }^{-}$ & -0.17 & -0.5 &  &  & (-0.67, 0.36)$^{\prime }$ & 
(-0.88, 0.12)$^{\prime }$ \\ 
$\mathbf{\mu }^{+}$ & 0.68 & 1.31 &  &  & (0.02, 1.28)$^{\prime }$ & (0.49,
1.67)$^{\prime }$ \\ 
$\rho ^{-}$ &  & 0.3 &  &  &  & 0.3 \\ 
$\rho ^{+}$ &  & 0.6 &  &  &  & 0.6 \\ 
$\mathbf{\gamma }^{0}$ &  &  & (0.5, 0.6)$^{\prime }$ & (0.5, 0.6)$^{\prime }
$ &  &  \\ 
$\mathbf{\mu }^{0}$ &  &  & (-1.45, -0.55, 0.75, 1.65)$^{^{\prime }}$ & 
(-1.18,-0.33, 0.9, 1.76)$^{^{\prime }}$ &  &  \\ 
$\rho ^{0}$ &  &  &  & 0.5 &  &  \\ 
\bottomrule &  &  &  &  &  & 
\end{tabular}
}
\end{table}

Table \ref{table:errors} reports the following measures of accuracy computed
for the estimates of the parameters, probabilities and PE: \emph{Bias} ---
the absolute difference between the estimated and true values, devided by
the true value, averaged over all Monte Carlo runs, in percent; \emph{RMSE}
--- the absolute root mean square error of the parameter estimates relative
to their true values, averaged over all replications; \emph{CP} --- the
empirical coverage probability, computed as the percentage of times the
estimated asymptotic 95\% confidence intervals cover the true values. To
measure the accuracy of the estimates of the standard errors, we also
computed the \emph{s.e.} \emph{bias} --- the absolute difference between the
average of the estimated asymptotic standard errors of the estimates and the
standard deviation of the estimates in all replications, in percent. The
above measures of accuracy computed for the estimates of the parameters are
averaged across all parameters, for the estimates of the probabilities ---
averaged across five outcome categories, and for the estimates of the PEs
--- averaged across five outcome categories and across all covariates.

The simulations and estimations were performed using the MATA programming
language. The starting values for $\mathbf{\alpha }$, $\mathbf{\beta }$, $%
\mathbf{\beta }^{0}$, $\mathbf{\mu }^{0}$, $\mathbf{\mu }^{+},$ $\mathbf{%
\gamma }^{+}$, $\mathbf{\mu }^{-}$ and $\mathbf{\gamma }^{-}$ were obtained
using the independent OP estimations of each latent equation. The starting
values for each independent OP model were computed using the linear OLS
estimations. The starting values for $\rho ^{0}$, $\rho ^{-}$ and $\rho ^{+}$
were obtained by maximizing the logarithms of the likelihood functions of
the correlated models holding the other parameters fixed at their estimates
in the corresponding uncorrelated model.

\subsection*{Results of simulations}

For each model specification, bias and RMSE of parameter estimates decrease
as sample size increases. RMSE decreases in most cases faster than
asymptotic rate $\sqrt{n}$. This may be caused by a small number of large
deviations in parameter estimation on small samples.

For most of model pairs and sample sizes, bias and RMSE is slightly higher
for the correlated version. This is expected from a more complex model,
estimated on the same sample size.

Standard error estimates for parameters on average correspond to the actual
standard errors. Large deviations make standard errors estimates biased,
especially on small samples, but this problem rapidly decreases with sample
size. Anyway, rare large deviations do not prevent asymptotic coverage
probabilities of 95\% confidence intervals from being consistent. This means
that confidence intervals for parameter estimates may be used safely.

For estimates of outcome probabilities and marginal effects the situation is
qualitatively and quantitatively similar to estimates of parameters.

In general, results of Monte Carlo simulations show that estimators of CNOP
family are consistent, but should be used carefully on small samples. As a
rule of thumb, we would advise using at least 10 observations per variable
in each outcome class, which corresponds to 1000 observations in our case.

\section{\protect\Large The (correlated) nested ordered probit model}

Left out

\section*{\protect\Large A special case when the CNOP model nests the MIOP
model\ }

Left out

% Need to insert \midrule between parts of table and 4cm width of multirows instead of * manually
% Need \usepackage{booktabs} and \usepackage{multirow}
% Table generated by Excel2LaTeX from sheet 'total'. 

\begin{table}[htbp]
\caption{Monte Carlo simulations for different models and sample sizes}
\label{table:errors}\centering
\begin{tabular}{rrcccccc}
\toprule \toprule Sample size & \multicolumn{1}{c}{DGP:} & NOP & NOPc & ZIOP
& ZIOPc & CNOP & CNOPc \\ 
\multicolumn{8}{c}{Parameters} \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[1]{*}{Bias, \%}} & 
12.8 & 19.5 & 42.3 & 11.3 & 59.4 & 89.4 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 4.8 & 12.2 & 3.8 & 3.7 & 
20.9 & 19.6 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 2.2 & 5.2 & 1.8 & 1.7 & 8.9
& 5.9 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{*}{RMSE}} & 0.51
& 0.86 & 1.40 & 0.37 & 0.45 & 1.03 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 0.15 & 0.20 & 0.17 & 0.19 & 
0.21 & 0.29 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 0.10 & 0.15 & 0.10 & 0.12
& 0.14 & 0.18 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{4cm}{Coverage
probability (at 95\% level), \%}} & 95.3 & 88.4 & 93.4 & 90.0 & 92.0 & 84.7
\\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 95.1 & 90.5 & 94.4 & 92.9 & 
93.1 & 88.9 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 95.3 & 92.1 & 95.1 & 94.8
& 93.8 & 91.7 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{4cm}{Bias of
standard error estimates, \%}} & 19.3 & 16.0 & 39.5 & 16.1 & 22.8 & 12.7 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 2.5 & 4.2 & 11.2 & 6.9 & 8.1
& 17.3 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 1.6 & 3.4 & 4.8 & 3.6 & 3.4
& 5.1 \\ 
\multicolumn{8}{c}{Probabilities} \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[1]{*}{Bias, \%}} & 
2.3 & 1.5 & 4.4 & 5.1 & 3.3 & 3.1 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 1.1 & 0.9 & 2.3 & 3.0 & 1.6
& 1.5 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 0.4 & 0.4 & 1.3 & 1.7 & 0.8
& 1.0 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{*}{RMSE}} & 0.02
& 0.03 & 0.03 & 0.03 & 0.03 & 0.03 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 0.01 & 0.02 & 0.02 & 0.02 & 
0.02 & 0.02 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 0.01 & 0.01 & 0.01 & 0.01
& 0.01 & 0.01 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{4cm}{Coverage
probability (at 95\% level), \%}} & 94.4 & 94.4 & 95.3 & 95.3 & 95.1 & 94.8
\\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 95.4 & 95.2 & 95.6 & 95.6 & 
95.9 & 95.7 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 95.5 & 95.5 & 95.7 & 95.7
& 95.6 & 95.6 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{4cm}{Bias of
standard error estimates, \%}} & 4.2 & 4.2 & 6.8 & 6.4 & 5.5 & 15.1 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 3.9 & 4.6 & 6.9 & 6.1 & 5.3
& 16.6 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 2.6 & 3.4 & 5.7 & 5.9 & 3.7
& 13.9 \\ 
\multicolumn{8}{c}{Marginal effects on probabilities} \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[1]{*}{Bias, \%}} & 
4.5 & 4.1 & 10.6 & 16.9 & 11.5 & 23.0 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 1.7 & 2.2 & 4.9 & 7.2 & 5.5
& 9.7 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 0.8 & 1.3 & 2.5 & 3.7 & 2.6
& 5.3 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{*}{RMSE}} & 0.02
& 0.02 & 0.02 & 0.04 & 0.03 & 0.03 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 0.01 & 0.01 & 0.01 & 0.02 & 
0.02 & 0.02 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 0.01 & 0.01 & 0.01 & 0.02
& 0.01 & 0.01 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{4cm}{Coverage
probability (at 95\% level), \%}} & 89.4 & 87.7 & 91.7 & 87.9 & 94.6 & 91.8
\\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 89.5 & 88.3 & 94.8 & 91.5 & 
95.0 & 93.0 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 89.3 & 88.6 & 95.3 & 93.9
& 95.1 & 93.9 \\ 
\multicolumn{1}{l}{200} & \multicolumn{1}{l}{\multirow{3}[2]{4cm}{Bias of
standard error estimates, \%}} & 4.7 & 5.7 & 8.1 & 6.1 & 21.4 & 39.1 \\ 
\multicolumn{1}{l}{500} & \multicolumn{1}{l}{} & 4.0 & 5.0 & 5.8 & 6.0 & 28.2
& 8.1 \\ 
\multicolumn{1}{l}{1000} & \multicolumn{1}{l}{} & 2.4 & 3.4 & 4.2 & 5.7 & 
12.7 & 7.4 \\ 
\bottomrule \bottomrule &  &  &  &  &  &  & 
\end{tabular}%
\end{table}

\end{document}
